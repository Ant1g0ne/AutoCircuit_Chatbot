import random
import streamlit as st
from collections import Counter
from utils import (
    load_data,
    load_keywords,
    search_topk,
    DATA_CSV_DEFAULT,
    KEYWORDS_TXT_DEFAULT,
)

st.set_page_config(page_title="AutoCircuit Chatbot", layout="wide")

st.title("AutoCircuit Chatbot")
st.caption("å¤šè½®é€‰æ‹©é¢˜å¼•å¯¼ Â· ç¨³å®šå®šä½è½¦è¾†ç”µè·¯å›¾æ–‡æ¡£")

# =========================
# Session State åˆå§‹åŒ–
# =========================
for key, default in {
    "res_full": None,
    "selected_brand": None,
    "selected_model": None,
    "search_history": [],
    "current_search_entry": None,  # ç”¨æ¥å­˜å‚¨å½“å‰æ­£åœ¨è¿›è¡Œçš„æœç´¢æ¡ç›®
}.items():
    if key not in st.session_state:
        st.session_state[key] = default

# =========================
# ä¾§è¾¹æ 
# =========================
with st.sidebar:
    st.header("æ•°æ®é…ç½®")
    csv_path = st.text_input("èµ„æ–™æ¸…å•.csv è·¯å¾„", value=DATA_CSV_DEFAULT)

    st.divider()
    st.header("æ£€ç´¢å‚æ•°")
    st.caption("æ ¹æ®æ‚¨çš„éœ€æ±‚è°ƒæ•´æ£€ç´¢å‚æ•°ã€‚")
    k = st.slider("æœ€ç»ˆè¿”å›æ¡æ•° k", 1, 10, 5, help="è®¾ç½®è¿”å›çš„æ–‡æ¡£æ•°é‡")
    candidate_pool = st.slider("å€™é€‰æ± å¤§å°", 30, 200, 100, step=10, help="å€™é€‰æ–‡æ¡£æ± å¤§å°")
    min_score = st.slider("æœ€ä½ç›¸å…³æ€§åˆ†æ•°", 0, 100, 55, step=1, help="è®¾ç½®æœ€ä½ç›¸å…³æ€§åˆ†æ•°")

    st.divider()
    use_llm = st.checkbox("å¯ç”¨ LLM æ„å›¾è¾…åŠ©", value=False, help="å¯ç”¨ GPT-4o-mini è§£æç”¨æˆ·è¾“å…¥ï¼Œæå‡æ£€ç´¢ç²¾åº¦")

    st.divider()
    if st.button("ğŸ”„ é‡æ–°å¼€å§‹"):
        st.session_state.clear()
        st.session_state.search_history = []  # æ¸…ç©ºæœç´¢å†å²
        st.session_state.current_search_entry = None  # æ¸…ç©ºå½“å‰æœç´¢æ¡ç›®
        st.rerun()  # æ”¹ä¸º st.rerun()

@st.cache_data(show_spinner=True)
def cached_load(csv_path: str):
    return load_data(csv_path)

try:
    df = cached_load(csv_path)
    st.success(f"æ•°æ®åŠ è½½æˆåŠŸï¼š{len(df)} æ¡")
except Exception as e:
    st.error(f"æ•°æ®åŠ è½½å¤±è´¥ï¼š{e}")
    st.stop()

tab1, tab2 = st.tabs(["ğŸ” æŸ¥è¯¢", "ğŸ§ª keywords.txt æŠ½æµ‹"])

# =========================
# å·¥å…·å‡½æ•°
# =========================
def extract_brand(path: str):
    parts = str(path).split("->")
    for i, p in enumerate(parts):
        if p in ("å·¥ç¨‹æœºæ¢°", "å•†ç”¨è½¦"):
            if i + 1 < len(parts):
                return parts[i + 1]
    return None

def extract_model(path: str):
    parts = str(path).split("->")
    if len(parts) >= 2:
        return parts[-1]
    return None

# =========================
# æŸ¥è¯¢ + åŒè½®å¼•å¯¼
# =========================
def query_search():
    query = st.session_state.query_input  # ä½¿ç”¨ text_input è·å–å®æ—¶è¾“å…¥å†…å®¹
    if query.strip():
        with st.spinner("æ£€ç´¢ä¸­..."):
            st.session_state.res_full = search_topk(
                df,
                query=query,
                k=candidate_pool,
                candidate_pool=candidate_pool,
                min_score=min_score,
                use_llm_intent=use_llm,
            )
        # åˆ›å»ºæ–°çš„æœç´¢æ¡ç›®
        st.session_state.current_search_entry = {
            "query": query,
            "brand": None,
            "model": None,
        }

# ç›‘å¬å›è½¦äº‹ä»¶ï¼Œè§¦å‘æŸ¥è¯¢
st.text_input(
    "è¯·è¾“å…¥ä½ çš„æŸ¥è¯¢ï¼ˆè‡ªç„¶è¯­è¨€ / å…³é”®è¯ï¼‰",
    placeholder="ä¾‹å¦‚ï¼š4HK1ä½å‹ecuç”µè·¯å›¾ / ä¸œé£å¤©é¾™ä»ªè¡¨å›¾",
    key="query_input",  # ä½¿ç”¨ `key` è®©å®ƒèƒ½å®æ—¶åŒæ­¥åˆ° `st.session_state.query_input`
    on_change=query_search  # å›è½¦æ—¶è§¦å‘æŸ¥è¯¢
)

# æ·»åŠ ä¸€ä¸ªâ€œæœç´¢â€æŒ‰é’®
if st.button("æœç´¢"):
    query_search()  # ç‚¹å‡»æœç´¢æŒ‰é’®åè¿›è¡ŒæŸ¥è¯¢

res = st.session_state.res_full
if res is None or res.empty:
    st.stop()

# =========================
# å·²é€‰æ¡ä»¶å±•ç¤ºï¼ˆUX æ ¸å¿ƒï¼‰ 
# =========================
st.markdown("### âœ… å·²é€‰æ‹©æ¡ä»¶")
if st.session_state.current_search_entry["brand"]:
    st.write(f"- å“ç‰Œï¼š{st.session_state.current_search_entry['brand']}")
if st.session_state.current_search_entry["model"]:
    st.write(f"- å‹å·ï¼š{st.session_state.current_search_entry['model']}")
if not st.session_state.current_search_entry["brand"] and not st.session_state.current_search_entry["model"]:
    st.caption("ï¼ˆå°šæœªé€‰æ‹©ä»»ä½•ç­›é€‰æ¡ä»¶ï¼‰")

# =========================
# ç¬¬ä¸€è½®ï¼šå“ç‰Œ
# =========================
if st.session_state.current_search_entry["brand"] is None:
    st.subheader("è¯·é€‰æ‹©å“ç‰Œ")
    brands = [extract_brand(p) for p in res["å±‚çº§è·¯å¾„"] if extract_brand(p)]
    counter = Counter(brands).most_common(5)

    num_cols = max(1, len(counter))  # å¦‚æœ counter ä¸ºç©ºï¼Œè‡³å°‘ä¸º 1 åˆ—
    cols = st.columns(num_cols)

    for i, (b, c) in enumerate(counter):
        with cols[i]:
            if st.button(f"{b}ï¼ˆ{c}ï¼‰"):
                st.session_state.current_search_entry["brand"] = b
                if st.session_state.current_search_entry["brand"] and st.session_state.current_search_entry["model"]:
                    st.session_state.search_history.append(st.session_state.current_search_entry.copy())
                st.rerun()  # æ”¹ä¸º st.rerun()

# åº”ç”¨å“ç‰Œè¿‡æ»¤
if st.session_state.current_search_entry["brand"]:
    res = res[res["å±‚çº§è·¯å¾„"].str.contains(st.session_state.current_search_entry["brand"])]

# =========================
# ç¬¬äºŒè½®ï¼šå‹å·
# =========================
if st.session_state.current_search_entry["brand"] and st.session_state.current_search_entry["model"] is None:
    if len(res) > k:
        st.subheader("è¯·é€‰æ‹©å‹å· / ç³»åˆ—")
        models = [extract_model(p) for p in res["å±‚çº§è·¯å¾„"] if extract_model(p)]
        counter = Counter(models).most_common(5)

        cols = st.columns(len(counter))
        for col, (m, c) in zip(cols, counter):
            with col:
                if st.button(f"{m}ï¼ˆ{c}ï¼‰"):
                    st.session_state.current_search_entry["model"] = m
                    if st.session_state.current_search_entry["brand"] and st.session_state.current_search_entry["model"]:
                        st.session_state.search_history.append(st.session_state.current_search_entry.copy())
                    st.rerun()  # æ”¹ä¸º st.rerun()

# åº”ç”¨å‹å·è¿‡æ»¤
if st.session_state.current_search_entry["model"]:
    res = res[res["å±‚çº§è·¯å¾„"].str.contains(st.session_state.current_search_entry["model"])]

# =========================
# æœ€ç»ˆç»“æœ
# =========================
st.subheader("ğŸ“„ åŒ¹é…ç»“æœ")
if res.empty:
    st.warning("ç­›é€‰åæ— ç»“æœï¼Œå¯å°è¯•é‡æ–°å¼€å§‹ã€‚")
else:
    st.dataframe(res.head(k), use_container_width=True)

# =========================
# æ˜¾ç¤ºæœç´¢å†å²
# =========================
with st.expander("ğŸ•’ æœç´¢å†å²", expanded=True):
    if st.session_state.search_history:
        for entry in st.session_state.search_history:
            st.write(f"**æŸ¥è¯¢**: {entry['query']}")
            if entry["brand"]:
                st.write(f"- **å“ç‰Œ**: {entry['brand']}")
            if entry["model"]:
                st.write(f"- **å‹å·**: {entry['model']}")
            st.markdown("---")
    else:
        st.caption("æ²¡æœ‰æœç´¢å†å²ã€‚")
